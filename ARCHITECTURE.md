# Product Architecture - Equity Research Intelligence Platform

## Executive Summary

An AI-powered equity research platform that democratizes institutional-grade analysis by combining real-time data aggregation, automated research generation, and collaborative intelligence. The platform enables natural language prompts to generate comprehensive research reports, financial models, and investment theses in minutes rather than weeks.

**Vision**: "Lovable for Equity Research" - making professional-grade equity analysis accessible through AI automation.

---

## Table of Contents

1. [System Architecture](#system-architecture)
2. [Core Components](#core-components)
3. [UI/UX Architecture](#uiux-architecture)
4. [AI/ML Architecture](#aiml-architecture)
5. [Data Architecture](#data-architecture)
6. [Technology Stack](#technology-stack)
7. [Security & Compliance](#security--compliance)
8. [Deployment & Infrastructure](#deployment--infrastructure)
9. [Integration Points](#integration-points)
10. [Development Roadmap](#development-roadmap)

---

## System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Client Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Next.js Application (Vercel)                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚  â”‚ Dashboard  â”‚  â”‚ Research   â”‚  â”‚ Data       â”‚             â”‚   â”‚
â”‚  â”‚  â”‚ View       â”‚  â”‚ Studio     â”‚  â”‚ Explorer   â”‚             â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Edge Layer (Vercel)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  API Routes  â”‚  Middleware  â”‚  Auth  â”‚  Rate Limiting       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend Layer (Supabase)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ PostgreSQL   â”‚  â”‚ Auth         â”‚  â”‚ Storage      â”‚              â”‚
â”‚  â”‚ Database     â”‚  â”‚ Service      â”‚  â”‚ (Reports)    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Realtime     â”‚  â”‚ Edge         â”‚  â”‚ Vector DB    â”‚              â”‚
â”‚  â”‚ Subscriptionsâ”‚  â”‚ Functions    â”‚  â”‚ (pgvector)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI Orchestration Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              IBM watsonx Orchestrate                          â”‚   â”‚
â”‚  â”‚                                                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚           Multi-Agent Research System                  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Analyst Agent    â€¢ Quantitative Agent              â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Risk Agent       â€¢ Fact-Checker Agent              â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Writer Agent     â€¢ Orchestrator                  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚              IBM watsonx.ai                            â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Foundation Models (Granite, Llama)                 â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Fine-tuned Financial Models                        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ RAG for Context Enhancement                        â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Aggregation Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Market Data  â”‚  â”‚ Fundamentals â”‚  â”‚ Alternative  â”‚              â”‚
â”‚  â”‚ Providers    â”‚  â”‚ Data         â”‚  â”‚ Data         â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ News & NLP   â”‚  â”‚ SEC EDGAR    â”‚  â”‚ Earnings     â”‚              â”‚
â”‚  â”‚ Services     â”‚  â”‚ Filings      â”‚  â”‚ Transcripts  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Components

### 1. Research Studio (Core Interface)

The Research Studio is the heart of the platform, providing an immersive environment for creating and managing equity research.

#### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Research Studio Layout                    â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Left   â”‚  â”‚      Center Stage         â”‚  â”‚  Right   â”‚  â”‚
â”‚  â”‚ Sidebar â”‚  â”‚                           â”‚  â”‚  Panel   â”‚  â”‚
â”‚  â”‚         â”‚  â”‚   Research Document       â”‚  â”‚          â”‚  â”‚
â”‚  â”‚ â€¢ Co.   â”‚  â”‚   with Live Editing       â”‚  â”‚ â€¢ AI     â”‚  â”‚
â”‚  â”‚   Tree  â”‚  â”‚                           â”‚  â”‚   Chat   â”‚  â”‚
â”‚  â”‚ â€¢ Data  â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚ â€¢ Data   â”‚  â”‚
â”‚  â”‚   Src   â”‚  â”‚   â”‚ Investment      â”‚     â”‚  â”‚   Exp.   â”‚  â”‚
â”‚  â”‚ â€¢ Templ â”‚  â”‚   â”‚ Thesis          â”‚     â”‚  â”‚ â€¢ Cite   â”‚  â”‚
â”‚  â”‚   Lib   â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚   Mgr    â”‚  â”‚
â”‚  â”‚         â”‚  â”‚                           â”‚  â”‚          â”‚  â”‚
â”‚  â”‚         â”‚  â”‚   Section 1...            â”‚  â”‚          â”‚  â”‚
â”‚  â”‚         â”‚  â”‚   Section 2...            â”‚  â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Bottom Dock (Expandable)                â”‚  â”‚
â”‚  â”‚  ðŸ“Š Charts  â”‚  ðŸ“‹ Tables  â”‚  ðŸ§® Models  â”‚  ðŸ“ˆ Data   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Component Structure

```typescript
// Research Studio Component Hierarchy
ResearchStudio/
â”œâ”€â”€ LayoutContainer
â”‚   â”œâ”€â”€ TopBar (Save status, Export, Share, Settings)
â”‚   â”œâ”€â”€ LeftSidebar
â”‚   â”‚   â”œâ”€â”€ CompanySelector (with search & favorites)
â”‚   â”‚   â”œâ”€â”€ DataSourcePanel (toggle data streams)
â”‚   â”‚   â””â”€â”€ TemplateLibrary (drag & drop templates)
â”‚   â”œâ”€â”€ CenterStage
â”‚   â”‚   â”œâ”€â”€ DocumentEditor (rich text with financial blocks)
â”‚   â”‚   â”œâ”€â”€ OutlineView (collapsible sections)
â”‚   â”‚   â””â”€â”€ LivePreview (real-time rendering)
â”‚   â”œâ”€â”€ RightPanel
â”‚   â”‚   â”œâ”€â”€ AIAssistant (chat interface)
â”‚   â”‚   â”œâ”€â”€ DataExplorer (metrics, charts)
â”‚   â”‚   â””â”€â”€ CitationManager (sources tracking)
â”‚   â””â”€â”€ BottomDock
â”‚       â”œâ”€â”€ ChartBuilder (interactive charting)
â”‚       â”œâ”€â”€ TableBuilder (data grids)
â”‚       â”œâ”€â”€ ModelBuilder (financial models)
â”‚       â””â”€â”€ DataFeed (live data streams)
```

#### Key Features

**Chat-to-Research Engine**:
- Natural language research generation
- Iterative refinement with context retention
- Multi-turn conversations with memory
- Smart suggestion system

**Progressive Disclosure**:
- Start: Simple prompt â†’ AI generates outline
- Expand: Outline â†’ Full sections with data
- Deep Dive: Summary â†’ Detailed analysis â†’ Raw data
- Custom: User modifies and AI adapts

**Auto-Save & Versioning**:
- Auto-save every 30 seconds
- Version history with diff viewing
- Branch/merge research documents
- Collaboration with conflict resolution

### 2. Dashboard (Home View)

#### Layout Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ  Dashboard                          [User] [Settings]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚          ðŸ“Š Market Pulse (Top Ticker)                â”‚ â”‚
â”‚  â”‚  Major Movers | Earnings Today | Macro Events        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   ðŸ“ Your Coverage      â”‚  â”‚  ðŸ”„ Research Pipelineâ”‚   â”‚
â”‚  â”‚   (Portfolio View)      â”‚  â”‚  In-progress reports â”‚   â”‚
â”‚  â”‚                         â”‚  â”‚  with % completion   â”‚   â”‚
â”‚  â”‚   NVDA  âœ… Current      â”‚  â”‚                      â”‚   â”‚
â”‚  â”‚   AAPL  â³ Updating     â”‚  â”‚  AMD Analysis - 67%  â”‚   â”‚
â”‚  â”‚   MSFT  ðŸ”´ Outdated     â”‚  â”‚  Tech Sector - 23%   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           ðŸ’¡ AI Insights Feed                        â”‚ â”‚
â”‚  â”‚  Daily highlights from your watchlist                â”‚ â”‚
â”‚  â”‚                                                       â”‚ â”‚
â”‚  â”‚  â€¢ NVDA: Gross margins expanded 200bps QoQ          â”‚ â”‚
â”‚  â”‚  â€¢ AAPL: China revenue declined 8% - risk to thesis â”‚ â”‚
â”‚  â”‚  â€¢ Semiconductor sector: New export restrictions    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Dashboard Components

```typescript
Dashboard/
â”œâ”€â”€ MarketPulse
â”‚   â”œâ”€â”€ MajorMovers (top gainers/losers)
â”‚   â”œâ”€â”€ EarningsCalendar (upcoming earnings)
â”‚   â””â”€â”€ MacroEvents (Fed meetings, GDP, CPI)
â”œâ”€â”€ PortfolioView
â”‚   â”œâ”€â”€ CoverageList (user's companies)
â”‚   â”œâ”€â”€ StatusIndicators (current/stale/updating)
â”‚   â””â”€â”€ QuickActions (open, update, archive)
â”œâ”€â”€ ResearchPipeline
â”‚   â”œâ”€â”€ InProgressReports (with progress bars)
â”‚   â”œâ”€â”€ DraftQueue
â”‚   â””â”€â”€ ScheduledUpdates
â””â”€â”€ InsightsFeed
    â”œâ”€â”€ AIGeneratedInsights (daily)
    â”œâ”€â”€ MaterialEvents (8-K filings, news)
    â””â”€â”€ PersonalizedAlerts
```

### 3. Data Explorer

Interactive tool for ad-hoc analysis and data discovery.

```typescript
DataExplorer/
â”œâ”€â”€ CompanySearch (autocomplete with metadata)
â”œâ”€â”€ MetricSelector
â”‚   â”œâ”€â”€ Fundamentals (P/E, EV/EBITDA, margins)
â”‚   â”œâ”€â”€ Growth (revenue, earnings growth)
â”‚   â”œâ”€â”€ Quality (ROIC, FCF conversion)
â”‚   â””â”€â”€ Custom (user-defined formulas)
â”œâ”€â”€ VisualizationEngine
â”‚   â”œâ”€â”€ TimeSeriesChart (historical trends)
â”‚   â”œâ”€â”€ ComparisonChart (peer benchmarking)
â”‚   â”œâ”€â”€ ScatterPlot (correlation analysis)
â”‚   â””â”€â”€ HeatMap (sector comparison)
â”œâ”€â”€ DataGrid
â”‚   â”œâ”€â”€ Sortable columns
â”‚   â”œâ”€â”€ Filterable rows
â”‚   â””â”€â”€ Exportable (CSV, Excel, PDF)
â””â”€â”€ SavedViews (bookmarked analyses)
```

---

## UI/UX Architecture

### Design System

#### Color System

```javascript
// colors.ts
export const colors = {
  // Performance Indicators
  performance: {
    positive: '#10B981', // Green - outperformance
    negative: '#EF4444', // Red - underperformance
    neutral: '#6B7280',  // Gray
  },

  // Data Categories
  data: {
    historical: '#3B82F6',  // Blue - facts, historical
    forecast: '#8B5CF6',    // Purple - projections
    aiGenerated: '#A855F7', // Light purple - AI content
  },

  // Alerts & Warnings
  alerts: {
    warning: '#F59E0B',  // Yellow - attention needed
    risk: '#EF4444',     // Red - high risk
    opportunity: '#10B981', // Green - positive signal
  },

  // UI Elements
  ui: {
    primary: '#1F2937',   // Dark gray
    secondary: '#6B7280', // Medium gray
    background: '#FFFFFF', // White (light mode)
    backgroundDark: '#111827', // Dark mode
  }
};
```

#### Typography System

```javascript
// typography.ts
export const typography = {
  // UI Elements (Sans-serif)
  ui: {
    fontFamily: 'Inter, system-ui, sans-serif',
    sizes: {
      xs: '0.75rem',   // 12px
      sm: '0.875rem',  // 14px
      base: '1rem',    // 16px
      lg: '1.125rem',  // 18px
      xl: '1.25rem',   // 20px
    }
  },

  // Research Content (Serif)
  content: {
    fontFamily: 'Georgia, serif',
    sizes: {
      body: '1.125rem',     // 18px
      heading: '1.5rem',    // 24px
      subheading: '1.25rem', // 20px
    }
  },

  // Financial Data (Monospace)
  data: {
    fontFamily: 'JetBrains Mono, Courier, monospace',
    sizes: {
      table: '0.875rem',  // 14px
      inline: '0.9375rem', // 15px
    }
  }
};
```

#### Component Library

```
components/
â”œâ”€â”€ atoms/
â”‚   â”œâ”€â”€ Button.tsx
â”‚   â”œâ”€â”€ Input.tsx
â”‚   â”œâ”€â”€ Badge.tsx (status indicators)
â”‚   â”œâ”€â”€ Tooltip.tsx
â”‚   â””â”€â”€ Icon.tsx
â”œâ”€â”€ molecules/
â”‚   â”œâ”€â”€ MetricCard.tsx (KPI display)
â”‚   â”œâ”€â”€ CompanyCard.tsx (company summary)
â”‚   â”œâ”€â”€ ChartContainer.tsx
â”‚   â”œâ”€â”€ TableHeader.tsx
â”‚   â””â”€â”€ SearchBar.tsx
â”œâ”€â”€ organisms/
â”‚   â”œâ”€â”€ NavigationBar.tsx
â”‚   â”œâ”€â”€ DataTable.tsx (sortable, filterable)
â”‚   â”œâ”€â”€ ChartBuilder.tsx
â”‚   â”œâ”€â”€ AIChat.tsx
â”‚   â””â”€â”€ DocumentEditor.tsx
â””â”€â”€ templates/
    â”œâ”€â”€ DashboardLayout.tsx
    â”œâ”€â”€ ResearchStudioLayout.tsx
    â””â”€â”€ DataExplorerLayout.tsx
```

### Interaction Patterns

#### Speed Optimizations

1. **Instant Feedback**:
   - Optimistic UI updates
   - Skeleton loaders during data fetch
   - Progressive loading (above-fold first)

2. **Smart Caching**:
   ```typescript
   // Cache strategy
   const cacheConfig = {
     marketData: { ttl: 60 }, // 1 minute
     fundamentals: { ttl: 3600 }, // 1 hour
     research: { ttl: 0 }, // Always fresh
     static: { ttl: 86400 }, // 24 hours
   };
   ```

3. **Prefetching**:
   - Hover intent detection
   - Predictive prefetching based on user patterns
   - Background data refresh

#### Progressive Disclosure

```
Level 1: Summary View
â”œâ”€ Investment Thesis (3 bullets)
â”œâ”€ Price Target & Rating
â””â”€ Key Metrics (5-6 core metrics)

Level 2: Detailed Sections (expand on click)
â”œâ”€ Business Overview
â”œâ”€ Financial Analysis
â”œâ”€ Competitive Position
â””â”€ Valuation

Level 3: Deep Data (modal or slide-in panel)
â”œâ”€ Full financial statements
â”œâ”€ Detailed comp tables
â”œâ”€ Model assumptions
â””â”€ Source documents
```

---

## AI/ML Architecture

### IBM watsonx Orchestrate Integration

#### Multi-Agent Research System

```python
# Agent Architecture
class ResearchOrchestrator:
    """
    Coordinates multiple AI agents to produce comprehensive research
    """

    def __init__(self):
        self.agents = {
            'analyst': AnalystAgent(),
            'quant': QuantitativeAgent(),
            'risk': RiskAgent(),
            'fact_checker': FactCheckerAgent(),
            'writer': WriterAgent(),
        }
        self.orchestrator = WatsonxOrchestrate()

    async def generate_research(
        self,
        prompt: str,
        company: str,
        report_type: str
    ) -> ResearchReport:
        """
        Orchestrates multi-agent workflow for research generation
        """
        # Phase 1: Data Collection & Initial Analysis
        analyst_insights = await self.agents['analyst'].analyze(
            company=company,
            prompt=prompt
        )

        # Phase 2: Quantitative Analysis
        financial_models = await self.agents['quant'].build_models(
            company=company,
            insights=analyst_insights
        )

        # Phase 3: Risk Assessment
        risk_analysis = await self.agents['risk'].assess_risks(
            company=company,
            models=financial_models
        )

        # Phase 4: Fact Checking
        validated_claims = await self.agents['fact_checker'].validate(
            claims=analyst_insights.claims,
            sources=analyst_insights.sources
        )

        # Phase 5: Report Writing
        report = await self.agents['writer'].synthesize(
            insights=analyst_insights,
            models=financial_models,
            risks=risk_analysis,
            validated_claims=validated_claims,
            template=report_type
        )

        return report
```

#### Agent Definitions

**1. Analyst Agent**
```python
class AnalystAgent:
    """
    Conducts qualitative research and identifies key insights
    """

    capabilities = [
        'Business model analysis',
        'Competitive positioning',
        'Industry trend identification',
        'Management assessment',
        'Strategic initiative evaluation'
    ]

    tools = [
        'web_search',
        'document_reader',
        'earnings_transcript_analyzer',
        'news_aggregator'
    ]
```

**2. Quantitative Agent**
```python
class QuantitativeAgent:
    """
    Builds financial models and runs quantitative analysis
    """

    capabilities = [
        'Three-statement model construction',
        'DCF valuation',
        'Comparable company analysis',
        'Scenario modeling',
        'Sensitivity analysis'
    ]

    tools = [
        'financial_data_api',
        'excel_model_builder',
        'statistical_analyzer',
        'regression_engine'
    ]
```

**3. Risk Agent**
```python
class RiskAgent:
    """
    Identifies and assesses business, financial, and regulatory risks
    """

    capabilities = [
        'Business risk identification',
        'Financial risk modeling',
        'Regulatory risk assessment',
        'ESG risk analysis',
        'Scenario-based stress testing'
    ]

    tools = [
        'risk_database',
        'regulatory_tracker',
        'news_sentiment_analyzer',
        'peer_risk_comparator'
    ]
```

**4. Fact-Checker Agent**
```python
class FactCheckerAgent:
    """
    Validates claims against authoritative data sources
    """

    capabilities = [
        'Source verification',
        'Data cross-referencing',
        'Calculation validation',
        'Citation generation',
        'Confidence scoring'
    ]

    tools = [
        'sec_edgar_api',
        'fact_database',
        'calculation_engine',
        'source_credibility_scorer'
    ]
```

**5. Writer Agent**
```python
class WriterAgent:
    """
    Synthesizes research into investment-grade prose
    """

    capabilities = [
        'Narrative construction',
        'Investment thesis formulation',
        'Executive summary generation',
        'Section organization',
        'Citation formatting'
    ]

    tools = [
        'llm_generator',
        'template_engine',
        'style_checker',
        'citation_formatter'
    ]
```

### Additional AI Recommendations

Beyond IBM watsonx, consider integrating:

#### 1. **LangChain / LlamaIndex**
For advanced RAG (Retrieval-Augmented Generation):
```python
from langchain.chains import RetrievalQA
from langchain.vectorstores import SupabaseVectorStore
from langchain.embeddings import OpenAIEmbeddings

# Build knowledge graph from past research
vector_store = SupabaseVectorStore(
    embedding=OpenAIEmbeddings(),
    table_name='research_embeddings'
)

qa_chain = RetrievalQA.from_chain_type(
    llm=watsonx_llm,
    retriever=vector_store.as_retriever()
)
```

#### 2. **OpenAI GPT-4 / Anthropic Claude**
For specific tasks where needed:
- GPT-4 Turbo: Fast responses for chat interface
- Claude 3 Opus: Long-context analysis (200K tokens) for full 10-K analysis

#### 3. **Hugging Face Models**
For specialized NLP tasks:
```python
specialized_models = {
    'sentiment': 'ProsusAI/finbert',  # Financial sentiment
    'ner': 'dslim/bert-base-NER',     # Named entity recognition
    'summarization': 'facebook/bart-large-cnn',
    'classification': 'yiyanghkust/finbert-tone'
}
```

#### 4. **AutoGen (Microsoft)**
For autonomous multi-agent collaboration:
```python
import autogen

# Define agent roles
analyst = autogen.AssistantAgent(name="analyst")
quant = autogen.AssistantAgent(name="quant")
critic = autogen.AssistantAgent(name="critic")

# Create group chat
groupchat = autogen.GroupChat(
    agents=[analyst, quant, critic],
    messages=[],
    max_round=12
)
```

### Personal Knowledge Graph

```sql
-- Schema for personalized learning
CREATE TABLE user_preferences (
    user_id UUID REFERENCES users(id),
    investment_style TEXT, -- value, growth, momentum
    risk_tolerance TEXT,   -- conservative, moderate, aggressive
    sectors_of_interest TEXT[],
    key_metrics TEXT[],
    preferred_valuation_methods TEXT[]
);

CREATE TABLE user_research_history (
    id UUID PRIMARY KEY,
    user_id UUID,
    company_ticker TEXT,
    research_type TEXT,
    key_insights JSONB,
    user_feedback TEXT, -- "helpful", "not relevant"
    created_at TIMESTAMP
);

-- Vector embeddings for similarity search
CREATE TABLE research_embeddings (
    id UUID PRIMARY KEY,
    user_id UUID,
    content TEXT,
    embedding vector(1536), -- Using pgvector
    metadata JSONB,
    created_at TIMESTAMP
);

CREATE INDEX ON research_embeddings
USING ivfflat (embedding vector_cosine_ops);
```

---

## Data Architecture

### Unified Data Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Ingestion Layer                       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Market   â”‚  â”‚ Fundamen-â”‚  â”‚ Alterna- â”‚             â”‚
â”‚  â”‚ Data     â”‚  â”‚ tals     â”‚  â”‚ tive Dataâ”‚             â”‚
â”‚  â”‚ APIs     â”‚  â”‚ Scrapers â”‚  â”‚ Feeds    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â”‚
â”‚       â”‚             â”‚             â”‚                    â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                     â”‚                                  â”‚
â”‚                     â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        Data Normalization Engine                â”‚   â”‚
â”‚  â”‚  â€¢ Standardize accounting treatments            â”‚   â”‚
â”‚  â”‚  â€¢ Currency conversion                          â”‚   â”‚
â”‚  â”‚  â€¢ Segment-level extraction                     â”‚   â”‚
â”‚  â”‚  â€¢ Time-series alignment                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                  â”‚
â”‚                     â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Data Quality Layer                     â”‚   â”‚
â”‚  â”‚  â€¢ Validation rules                             â”‚   â”‚
â”‚  â”‚  â€¢ Outlier detection                            â”‚   â”‚
â”‚  â”‚  â€¢ Gap filling                                  â”‚   â”‚
â”‚  â”‚  â€¢ Audit logging                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                  â”‚
â”‚                     â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        Supabase PostgreSQL Database             â”‚   â”‚
â”‚  â”‚  â€¢ Time-series tables                           â”‚   â”‚
â”‚  â”‚  â€¢ Normalized financials                        â”‚   â”‚
â”‚  â”‚  â€¢ Vector embeddings (pgvector)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Schema

```sql
-- Core Tables

-- Companies
CREATE TABLE companies (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    ticker TEXT UNIQUE NOT NULL,
    name TEXT NOT NULL,
    exchange TEXT,
    sector TEXT,
    industry TEXT,
    market_cap NUMERIC,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_companies_ticker ON companies(ticker);
CREATE INDEX idx_companies_sector ON companies(sector);

-- Market Data (Time-series)
CREATE TABLE market_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id),
    date DATE NOT NULL,
    open NUMERIC,
    high NUMERIC,
    low NUMERIC,
    close NUMERIC,
    volume BIGINT,
    adjusted_close NUMERIC,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_market_data_company_date
ON market_data(company_id, date DESC);

-- Financials (Quarterly/Annual)
CREATE TABLE financials (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id),
    period_end_date DATE NOT NULL,
    fiscal_period TEXT, -- Q1, Q2, Q3, Q4, FY
    fiscal_year INTEGER,

    -- Income Statement
    revenue NUMERIC,
    cost_of_revenue NUMERIC,
    gross_profit NUMERIC,
    operating_expenses NUMERIC,
    operating_income NUMERIC,
    net_income NUMERIC,
    eps_basic NUMERIC,
    eps_diluted NUMERIC,

    -- Balance Sheet
    total_assets NUMERIC,
    total_liabilities NUMERIC,
    shareholders_equity NUMERIC,
    cash NUMERIC,
    total_debt NUMERIC,

    -- Cash Flow
    operating_cash_flow NUMERIC,
    investing_cash_flow NUMERIC,
    financing_cash_flow NUMERIC,
    free_cash_flow NUMERIC,

    -- Metadata
    filing_type TEXT, -- 10-K, 10-Q
    source_url TEXT,
    raw_data JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_financials_company_period
ON financials(company_id, period_end_date DESC);

-- Alternative Data
CREATE TABLE alternative_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id),
    data_type TEXT, -- web_traffic, job_postings, satellite, etc.
    date DATE,
    metrics JSONB,
    source TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- News & Sentiment
CREATE TABLE news_articles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id),
    title TEXT,
    summary TEXT,
    url TEXT,
    published_at TIMESTAMP,
    source TEXT,
    sentiment_score NUMERIC, -- -1 to 1
    sentiment_label TEXT,    -- positive, negative, neutral
    relevance_score NUMERIC,
    created_at TIMESTAMP DEFAULT NOW()
);

-- SEC Filings
CREATE TABLE sec_filings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id),
    filing_type TEXT, -- 10-K, 10-Q, 8-K, etc.
    filing_date DATE,
    period_end_date DATE,
    accession_number TEXT UNIQUE,
    url TEXT,
    full_text TEXT,
    extracted_sections JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Research Reports
CREATE TABLE research_reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    company_id UUID REFERENCES companies(id),
    title TEXT,
    report_type TEXT, -- initiation, update, thematic, comp_analysis
    status TEXT,      -- draft, in_review, published, archived

    -- Investment Recommendation
    rating TEXT,      -- buy, hold, sell, strong_buy, strong_sell
    price_target NUMERIC,
    price_target_upside NUMERIC,

    -- Content
    content JSONB,    -- Structured sections
    summary TEXT,
    thesis TEXT[],    -- Investment thesis bullets

    -- AI Metadata
    ai_generated BOOLEAN DEFAULT false,
    ai_confidence_score NUMERIC,

    -- Version Control
    version INTEGER DEFAULT 1,
    parent_report_id UUID REFERENCES research_reports(id),

    -- Timestamps
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    published_at TIMESTAMP
);

CREATE INDEX idx_reports_user_company
ON research_reports(user_id, company_id);

-- Financial Models
CREATE TABLE financial_models (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    research_report_id UUID REFERENCES research_reports(id),
    company_id UUID REFERENCES companies(id),
    model_type TEXT, -- dcf, comp_analysis, lbo, sotp

    -- Model Data
    assumptions JSONB,
    projections JSONB,
    valuation_output JSONB,

    -- Scenarios
    bull_case JSONB,
    base_case JSONB,
    bear_case JSONB,

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Citations & Sources
CREATE TABLE citations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    research_report_id UUID REFERENCES research_reports(id),
    source_type TEXT, -- sec_filing, news, earnings_call, data_api
    source_id UUID,   -- References to source table
    claim TEXT,       -- The claim being supported
    page_number INTEGER,
    quote TEXT,
    confidence_score NUMERIC,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Vector Embeddings (for RAG)
CREATE TABLE embeddings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    content_type TEXT, -- research_report, filing, transcript
    content_id UUID,
    chunk_text TEXT,
    embedding vector(1536), -- Using pgvector extension
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX ON embeddings USING ivfflat (embedding vector_cosine_ops);

-- User Activity & Personalization
CREATE TABLE user_watchlists (
    user_id UUID REFERENCES users(id),
    company_id UUID REFERENCES companies(id),
    added_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (user_id, company_id)
);

CREATE TABLE user_preferences (
    user_id UUID PRIMARY KEY REFERENCES users(id),
    investment_style TEXT,
    risk_tolerance TEXT,
    preferred_sectors TEXT[],
    key_metrics TEXT[],
    notification_settings JSONB,
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Audit Trail (Compliance)
CREATE TABLE audit_log (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    action TEXT,      -- view, edit, publish, delete
    resource_type TEXT, -- research_report, financial_model
    resource_id UUID,
    ip_address INET,
    user_agent TEXT,
    timestamp TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_audit_log_user_timestamp
ON audit_log(user_id, timestamp DESC);
```

### Data Source Integrations

#### Market Data Providers

1. **Alpha Vantage** (Free tier available)
   - Real-time and historical stock prices
   - Technical indicators
   - Forex and crypto data

2. **Polygon.io**
   - Real-time market data
   - Options data
   - News and sentiment

3. **Yahoo Finance API** (Free)
   - Historical prices
   - Company fundamentals
   - News feed

#### Fundamental Data

1. **SEC EDGAR API** (Free)
   - All public company filings
   - Full-text search
   - RSS feeds for new filings

2. **Financial Modeling Prep API**
   - Financial statements
   - Key metrics
   - Historical data

3. **Intrinio**
   - Standardized financials
   - Company metadata
   - Institutional ownership

#### Alternative Data

1. **Web Traffic**: SimilarWeb API, Cloudflare Radar
2. **Job Postings**: Thinknum Alternative Data
3. **App Analytics**: Apptopia, Sensor Tower
4. **Satellite Imagery**: Orbital Insight, Descartes Labs
5. **Social Sentiment**: Twitter API, Reddit API, StockTwits

#### News & NLP

1. **News API**: Aggregates from 80,000+ sources
2. **Benzinga News API**: Real-time financial news
3. **Earnings Call Transcripts**: AlphaSense, Seeking Alpha

---

## Technology Stack

### Frontend (Next.js on Vercel)

```json
{
  "dependencies": {
    "next": "^14.0.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "typescript": "^5.0.0",

    "UI Framework": {
      "@radix-ui/react-*": "Latest",
      "tailwindcss": "^3.4.0",
      "framer-motion": "^10.0.0"
    },

    "State Management": {
      "zustand": "^4.5.0",
      "@tanstack/react-query": "^5.0.0"
    },

    "Data Visualization": {
      "recharts": "^2.10.0",
      "lightweight-charts": "^4.1.0",
      "plotly.js": "^2.27.0"
    },

    "Rich Text Editor": {
      "@tiptap/react": "^2.1.0",
      "@tiptap/starter-kit": "^2.1.0"
    },

    "Forms & Validation": {
      "react-hook-form": "^7.49.0",
      "zod": "^3.22.0"
    },

    "Date Handling": {
      "date-fns": "^3.0.0"
    },

    "Financial Calculations": {
      "mathjs": "^12.0.0",
      "finance": "^0.3.0"
    }
  }
}
```

#### Next.js Project Structure

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (auth)/
â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â””â”€â”€ signup/
â”‚   â”œâ”€â”€ (dashboard)/
â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Dashboard home
â”‚   â”‚   â”œâ”€â”€ research/
â”‚   â”‚   â”‚   â””â”€â”€ [reportId]/
â”‚   â”‚   â”‚       â””â”€â”€ page.tsx         # Research Studio
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx             # Data Explorer
â”‚   â”‚   â””â”€â”€ portfolio/
â”‚   â”‚       â””â”€â”€ page.tsx             # Coverage list
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ research/
â”‚   â”‚   â”‚   â”œâ”€â”€ generate/route.ts    # AI research generation
â”‚   â”‚   â”‚   â””â”€â”€ [id]/route.ts        # CRUD operations
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ market/route.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ fundamentals/route.ts
â”‚   â”‚   â”‚   â””â”€â”€ alternative/route.ts
â”‚   â”‚   â””â”€â”€ ai/
â”‚   â”‚       â”œâ”€â”€ chat/route.ts
â”‚   â”‚       â””â”€â”€ insights/route.ts
â”‚   â””â”€â”€ layout.tsx
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/                          # Base components
â”‚   â”œâ”€â”€ research/                    # Research Studio components
â”‚   â”œâ”€â”€ dashboard/                   # Dashboard components
â”‚   â””â”€â”€ data-explorer/               # Data Explorer components
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ supabase/                    # Supabase client & helpers
â”‚   â”œâ”€â”€ watsonx/                     # IBM watsonx integration
â”‚   â”œâ”€â”€ data-providers/              # Data API integrations
â”‚   â””â”€â”€ utils/                       # Utilities
â””â”€â”€ hooks/                           # Custom React hooks
```

### Backend (Supabase)

#### Supabase Configuration

```typescript
// lib/supabase/client.ts
import { createClient } from '@supabase/supabase-js'

export const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
)

// For server-side
import { createServerClient } from '@supabase/ssr'

export function createClient() {
  return createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        // Cookie handling for Next.js
      }
    }
  )
}
```

#### Supabase Features Used

1. **PostgreSQL Database**
   - Primary data storage
   - pgvector extension for embeddings
   - Full-text search
   - Row-level security (RLS)

2. **Authentication**
   - Email/password auth
   - OAuth providers (Google, GitHub)
   - Magic links
   - Multi-factor authentication

3. **Real-time Subscriptions**
   ```typescript
   // Subscribe to research report updates
   supabase
     .channel('research_updates')
     .on(
       'postgres_changes',
       {
         event: '*',
         schema: 'public',
         table: 'research_reports',
         filter: `user_id=eq.${userId}`
       },
       (payload) => {
         console.log('Change received!', payload)
       }
     )
     .subscribe()
   ```

4. **Storage**
   - Research report PDFs
   - Exported Excel models
   - User uploads (receipts, documents)

5. **Edge Functions** (Deno runtime)
   ```typescript
   // supabase/functions/process-filing/index.ts
   Deno.serve(async (req) => {
     const { filingUrl, companyId } = await req.json()

     // Process SEC filing
     const extractedData = await processSECFiling(filingUrl)

     // Store in database
     await supabaseAdmin
       .from('sec_filings')
       .insert({
         company_id: companyId,
         ...extractedData
       })

     return new Response(
       JSON.stringify({ success: true }),
       { headers: { 'Content-Type': 'application/json' } }
     )
   })
   ```

### AI/ML Stack

#### IBM watsonx Integration

```python
# lib/watsonx/client.py
from ibm_watson_machine_learning.foundation_models import Model
from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams

class WatsonxClient:
    def __init__(self):
        self.model = Model(
            model_id="ibm/granite-13b-chat-v2",
            credentials={
                "url": os.getenv("WATSONX_URL"),
                "apikey": os.getenv("WATSONX_API_KEY")
            },
            project_id=os.getenv("WATSONX_PROJECT_ID")
        )

    def generate_research(self, prompt: str, max_tokens: int = 4000):
        parameters = {
            GenParams.MAX_NEW_TOKENS: max_tokens,
            GenParams.TEMPERATURE: 0.7,
            GenParams.TOP_P: 0.9,
        }

        response = self.model.generate_text(
            prompt=prompt,
            params=parameters
        )

        return response
```

#### Additional AI Tools

```python
# requirements.txt
ibm-watson-machine-learning>=1.0.0
langchain>=0.1.0
llama-index>=0.9.0
openai>=1.0.0              # For GPT-4 fallback
anthropic>=0.7.0           # For Claude if needed
transformers>=4.35.0       # Hugging Face models
sentence-transformers>=2.2.0  # Embeddings
autogen-agentchat>=0.2.0   # Microsoft AutoGen
```

### Data Processing & Analytics

```python
# requirements.txt (Python)
pandas>=2.1.0
numpy>=1.24.0
scipy>=1.11.0
scikit-learn>=1.3.0
statsmodels>=0.14.0
yfinance>=0.2.0            # Yahoo Finance
alpha-vantage>=2.3.0       # Alpha Vantage API
sec-api>=1.0.0             # SEC EDGAR API
```

### Infrastructure & DevOps

```yaml
# docker-compose.yml (for local development)
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: finloggers
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  # For background jobs
  worker:
    build: ./worker
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/finloggers
      REDIS_URL: redis://redis:6379
    depends_on:
      - postgres
      - redis

volumes:
  postgres_data:
```

---

## Security & Compliance

### Authentication & Authorization

```typescript
// middleware.ts (Next.js)
import { createServerClient } from '@supabase/ssr'
import { NextResponse } from 'next/server'
import type { NextRequest } from 'next/server'

export async function middleware(request: NextRequest) {
  const supabase = createServerClient(...)

  const {
    data: { session },
  } = await supabase.auth.getSession()

  // Protected routes
  if (!session && request.nextUrl.pathname.startsWith('/dashboard')) {
    return NextResponse.redirect(new URL('/login', request.url))
  }

  return NextResponse.next()
}
```

### Row-Level Security (RLS)

```sql
-- Enable RLS on research_reports
ALTER TABLE research_reports ENABLE ROW LEVEL SECURITY;

-- Users can only see their own reports
CREATE POLICY "Users can view own reports"
ON research_reports
FOR SELECT
USING (auth.uid() = user_id);

-- Users can only insert their own reports
CREATE POLICY "Users can insert own reports"
ON research_reports
FOR INSERT
WITH CHECK (auth.uid() = user_id);

-- Users can only update their own reports
CREATE POLICY "Users can update own reports"
ON research_reports
FOR UPDATE
USING (auth.uid() = user_id);

-- Similar policies for other sensitive tables
```

### Data Encryption

1. **At Rest**:
   - Supabase handles database encryption
   - Storage bucket encryption enabled

2. **In Transit**:
   - HTTPS/TLS 1.3 for all connections
   - Secure WebSocket connections

3. **Application-Level**:
   ```typescript
   // Encrypt sensitive fields before storage
   import { encrypt, decrypt } from '@/lib/crypto'

   const encryptedData = encrypt(sensitiveInfo, process.env.ENCRYPTION_KEY)
   ```

### Compliance Features

#### MNPI (Material Non-Public Information) Safeguards

```sql
-- MNPI flagging system
CREATE TABLE mnpi_events (
    id UUID PRIMARY KEY,
    company_id UUID REFERENCES companies(id),
    event_type TEXT,
    start_date TIMESTAMP,
    end_date TIMESTAMP,
    description TEXT,
    created_by UUID REFERENCES users(id),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Restricted period tracking
CREATE TABLE user_restrictions (
    user_id UUID REFERENCES users(id),
    company_id UUID REFERENCES companies(id),
    restriction_type TEXT, -- blackout, watch_list
    reason TEXT,
    start_date TIMESTAMP,
    end_date TIMESTAMP,
    PRIMARY KEY (user_id, company_id, start_date)
);
```

#### Audit Trail

```typescript
// lib/audit.ts
export async function logAction(
  userId: string,
  action: string,
  resourceType: string,
  resourceId: string,
  metadata?: Record<string, any>
) {
  await supabase.from('audit_log').insert({
    user_id: userId,
    action,
    resource_type: resourceType,
    resource_id: resourceId,
    metadata,
    ip_address: req.ip,
    user_agent: req.headers['user-agent'],
  })
}

// Usage
await logAction(
  userId,
  'publish',
  'research_report',
  reportId,
  { rating: 'buy', price_target: 150 }
)
```

#### Source Citation Validation

```typescript
// Every claim must have a source
interface Claim {
  text: string
  source: {
    type: 'sec_filing' | 'earnings_call' | 'news' | 'data_api'
    sourceId: string
    page?: number
    quote?: string
    url?: string
  }
  confidence: number // 0-1
  verifiedAt: Date
}
```

---

## Deployment & Infrastructure

### Vercel Deployment

```json
// vercel.json
{
  "buildCommand": "next build",
  "devCommand": "next dev",
  "framework": "nextjs",
  "env": {
    "NEXT_PUBLIC_SUPABASE_URL": "@supabase-url",
    "NEXT_PUBLIC_SUPABASE_ANON_KEY": "@supabase-anon-key",
    "WATSONX_API_KEY": "@watsonx-api-key",
    "WATSONX_PROJECT_ID": "@watsonx-project-id"
  },
  "regions": ["iad1"],
  "functions": {
    "api/research/generate": {
      "maxDuration": 300
    }
  }
}
```

### Environment Variables

```bash
# .env.local
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...
SUPABASE_SERVICE_ROLE_KEY=eyJ...

# IBM watsonx
WATSONX_URL=https://us-south.ml.cloud.ibm.com
WATSONX_API_KEY=your-api-key
WATSONX_PROJECT_ID=your-project-id

# Data Providers
ALPHA_VANTAGE_API_KEY=your-key
POLYGON_API_KEY=your-key
FMP_API_KEY=your-key

# Optional: Additional AI providers
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
```

### Performance Optimization

#### Caching Strategy

```typescript
// lib/cache.ts
import { Redis } from '@upstash/redis'

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_URL,
  token: process.env.UPSTASH_REDIS_TOKEN,
})

export async function getCachedOrFetch<T>(
  key: string,
  fetcher: () => Promise<T>,
  ttl: number = 3600
): Promise<T> {
  // Try cache first
  const cached = await redis.get<T>(key)
  if (cached) return cached

  // Fetch and cache
  const data = await fetcher()
  await redis.set(key, data, { ex: ttl })

  return data
}

// Usage
const stockPrice = await getCachedOrFetch(
  `stock:${ticker}:price`,
  () => fetchStockPrice(ticker),
  60 // Cache for 1 minute
)
```

#### Database Optimization

```sql
-- Materialized view for common queries
CREATE MATERIALIZED VIEW mv_latest_financials AS
SELECT DISTINCT ON (company_id)
    company_id,
    period_end_date,
    revenue,
    net_income,
    eps_diluted,
    operating_cash_flow
FROM financials
ORDER BY company_id, period_end_date DESC;

CREATE UNIQUE INDEX ON mv_latest_financials (company_id);

-- Refresh strategy
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_latest_financials;
```

### Monitoring & Observability

```typescript
// Vercel Analytics
import { Analytics } from '@vercel/analytics/react'
import { SpeedInsights } from '@vercel/speed-insights/next'

export default function RootLayout({ children }) {
  return (
    <html>
      <body>
        {children}
        <Analytics />
        <SpeedInsights />
      </body>
    </html>
  )
}

// Custom error tracking
import * as Sentry from '@sentry/nextjs'

Sentry.init({
  dsn: process.env.NEXT_PUBLIC_SENTRY_DSN,
  tracesSampleRate: 1.0,
})
```

---

## Integration Points

### External Data Providers

#### Market Data Integration

```typescript
// lib/data-providers/alpha-vantage.ts
export class AlphaVantageClient {
  private apiKey: string

  async getStockPrice(ticker: string) {
    const response = await fetch(
      `https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=${ticker}&apikey=${this.apiKey}`
    )
    const data = await response.json()
    return {
      price: parseFloat(data['Global Quote']['05. price']),
      change: parseFloat(data['Global Quote']['09. change']),
      changePercent: parseFloat(data['Global Quote']['10. change percent']),
      timestamp: new Date()
    }
  }

  async getFinancials(ticker: string) {
    // Implementation for balance sheet, income statement, cash flow
  }
}
```

#### SEC EDGAR Integration

```python
# lib/data-providers/sec_edgar.py
import requests
from bs4 import BeautifulSoup

class SECEdgarClient:
    BASE_URL = "https://www.sec.gov"

    def __init__(self):
        self.headers = {
            'User-Agent': 'YourCompany contact@yourcompany.com'
        }

    def get_company_filings(self, cik: str, filing_type: str = "10-K"):
        """Fetch company filings from EDGAR"""
        url = f"{self.BASE_URL}/cgi-bin/browse-edgar"
        params = {
            'action': 'getcompany',
            'CIK': cik,
            'type': filing_type,
            'dateb': '',
            'owner': 'exclude',
            'count': 100,
            'output': 'xml'
        }

        response = requests.get(url, params=params, headers=self.headers)
        return self._parse_filings(response.content)

    def extract_financial_statements(self, filing_url: str):
        """Extract financial statements from 10-K/10-Q"""
        # Parse XBRL or HTML tables
        pass
```

### API Design

#### REST API Endpoints

```typescript
// API Routes Structure

// Research Reports
GET    /api/research                   # List all reports
POST   /api/research                   # Create new report
GET    /api/research/:id               # Get single report
PATCH  /api/research/:id               # Update report
DELETE /api/research/:id               # Delete report

// AI Generation
POST   /api/ai/generate                # Generate research from prompt
POST   /api/ai/chat                    # Chat with AI assistant
POST   /api/ai/insights                # Get AI insights for company

// Market Data
GET    /api/data/market/:ticker        # Real-time price
GET    /api/data/fundamentals/:ticker  # Financial statements
GET    /api/data/alternative/:ticker   # Alternative data

// Companies
GET    /api/companies                  # Search companies
GET    /api/companies/:ticker          # Company details

// Financial Models
POST   /api/models/dcf                 # Create DCF model
POST   /api/models/comps               # Comp analysis
GET    /api/models/:id                 # Get model

// User
GET    /api/user/watchlist             # User's watchlist
POST   /api/user/watchlist             # Add to watchlist
GET    /api/user/preferences           # User preferences
```

#### Example API Route

```typescript
// app/api/research/generate/route.ts
import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@/lib/supabase/server'
import { WatsonxOrchestrator } from '@/lib/watsonx/orchestrator'

export async function POST(req: NextRequest) {
  try {
    const supabase = createClient()

    // Verify authentication
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    if (authError || !user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    // Parse request
    const { prompt, ticker, reportType } = await req.json()

    // Create draft report
    const { data: report, error: dbError } = await supabase
      .from('research_reports')
      .insert({
        user_id: user.id,
        title: `${ticker} - ${reportType}`,
        status: 'generating',
        report_type: reportType,
      })
      .select()
      .single()

    if (dbError) throw dbError

    // Generate research (async)
    const orchestrator = new WatsonxOrchestrator()
    const generatedReport = await orchestrator.generateResearch({
      prompt,
      ticker,
      reportType,
      userId: user.id,
    })

    // Update report with content
    await supabase
      .from('research_reports')
      .update({
        content: generatedReport.content,
        status: 'draft',
        ai_generated: true,
      })
      .eq('id', report.id)

    return NextResponse.json({ reportId: report.id })

  } catch (error) {
    console.error('Research generation error:', error)
    return NextResponse.json(
      { error: 'Failed to generate research' },
      { status: 500 }
    )
  }
}
```

---

## Development Roadmap

### Phase 1: MVP (Months 1-3)

**Core Features**:
- âœ… User authentication (Supabase Auth)
- âœ… Dashboard with portfolio view
- âœ… Basic Research Studio with text editor
- âœ… Chat-to-Research (simple prompts â†’ reports)
- âœ… Market data integration (prices, basic financials)
- âœ… Template library (3-5 basic templates)
- âœ… PDF export

**AI Capabilities**:
- Single-agent research generation
- Basic financial analysis
- Simple valuation (P/E, EV/EBITDA)

### Phase 2: Enhanced Intelligence (Months 4-6)

**Features**:
- Multi-agent research system
- Financial modeling engine (DCF, comps)
- Alternative data integration (1-2 sources)
- Source citation system
- Version control for reports
- Collaborative editing

**AI Capabilities**:
- Analyst + Quant + Writer agents
- Automated financial modeling
- Fact-checking agent

### Phase 3: Advanced Analytics (Months 7-9)

**Features**:
- Personal knowledge graph
- Custom screening engine
- Real-time monitoring & alerts
- Advanced charting & visualization
- Thematic research templates
- Compliance features (audit trail, MNPI)

**AI Capabilities**:
- Full 5-agent system
- Personalized insights
- Predictive analytics
- Risk assessment automation

### Phase 4: Enterprise & Scale (Months 10-12)

**Features**:
- Team collaboration tools
- Admin dashboard
- White-labeling options
- API for third-party integrations
- Mobile app (React Native)
- Advanced compliance (SOC 2)

**AI Capabilities**:
- Custom fine-tuned models
- Multi-company thematic analysis
- Portfolio optimization suggestions
- Sentiment analysis at scale

---

## Appendix

### Key Metrics & KPIs

**Product Metrics**:
- Research reports generated per user/month
- Average time from prompt to published report
- User engagement (DAU/MAU)
- Feature adoption rates

**Technical Metrics**:
- API response times (p50, p95, p99)
- AI generation latency
- Database query performance
- Error rates

**Business Metrics**:
- User acquisition cost (CAC)
- Lifetime value (LTV)
- Monthly recurring revenue (MRR)
- Churn rate

### Cost Estimation

**Infrastructure** (Monthly):
- Vercel Pro: $20/month
- Supabase Pro: $25/month
- IBM watsonx: Pay-per-use (~$500-2000/month depending on usage)
- Data APIs: $100-500/month (Alpha Vantage, Polygon, etc.)
- Storage (S3/Supabase): $50-200/month

**Total**: ~$700-2,750/month for early stage

### Team Structure

**Recommended Initial Team**:
- 1x Full-stack Engineer (Next.js + Supabase)
- 1x AI/ML Engineer (watsonx integration, prompt engineering)
- 1x Data Engineer (data pipelines, ETL)
- 1x Product Designer (UI/UX)
- 1x Product Manager

### References

- [IBM watsonx Documentation](https://www.ibm.com/docs/en/watsonx)
- [Supabase Docs](https://supabase.com/docs)
- [Next.js Documentation](https://nextjs.org/docs)
- [SEC EDGAR API](https://www.sec.gov/edgar/sec-api-documentation)
- [Financial Modeling Best Practices](https://www.cfainstitute.org/)

---

**Document Version**: 1.0
**Last Updated**: 2025-11-18
**Authors**: Architecture Team
**Status**: Living Document

